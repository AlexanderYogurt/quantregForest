% \VignetteIndexEntry{Quantile Regression Forests}
% \VignetteDepends{randomForest}
% \VignetteKeyword{quantile regression forests}
% \VignetteKeyword{quantile regression}
% \VignetteKeyword{random forests}
% \VignetteKeyword{variable importance}
\documentclass{article}
\usepackage[utf8]{inputenx} \input{ix-utf8enc.dfu}
\usepackage[longnamesfirst]{natbib}
\usepackage{amsmath}
\title{Quantile Regression Forests - An R-Vignette}
\author{Lukas Schiesser}
\date{}
\begin{document}
\bibliographystyle{chicago}
\setcitestyle{authoryear, aysep={,},open{(},close{(}}
\SweaveOpts{concordance=TRUE}
\maketitle
\pagestyle{myheadings}
<<label=R options,echo=FALSE>>=
options(width = 60)
options(SweaveHooks = list(fig = function() par(mar=c(3,3,1,0.5),mgp = c(2,1,0))))
@
\section{Introduction}
The following few pages try to give a more detailed guideline to the use of quantile regression forests in R.\\
After installing the package it can be loaded by the command:
<<>>=
library(quantregForest)
@
\paragraph{Datasets}
Two datasets will be considered to illustrate how and when to use which methods for quantile regression forests. As example of a small dataset \textit{Ozone} from the package \verb+gss+ \citep{gss} with 330 observations of 10 variables and secondly a large data set named \textit{CASP} with $45'370$ available observations of 9 variables from the UCI Machine Learning Repository \citep{Lichman:2013} are used. In the following even not all observations of the second set are used since the desired effect can already be highlighted with less.
\section{Quantile Regression Forests}
\label{sec:2}
The first step when working with quantile regression forests is to grow such a forest.
The help file of the function \verb+quantregForest+
<<>>=
help(quantregForest)
@
specifies the right format for the input. The dataset has to be divided into predictor variables and a response variable. The predictor variables have to be made available either as a matrix or a data frame; the response has to be a numeric vector. Moreover the response has to be continuous. Binary or count responses are not allowed. The other input arguments are ignored for the moment and discussed later.\\
\\
The dataset \textit{Ozone} consists of 9 predictor variables and the response variable \textit{upo3} which is stored in the first column:
<<>>=
data(ozone,package="gss")
xozone <- ozone[-1]
yozone <- ozone$upo3
@
Now predictors \verb+xozone+ and response \verb+yozone+ can be given as input to \verb+quantregForest+:
<<>>=
qrfozone <- quantregForest(xozone,yozone)
@
The function \verb+quantregForest+ returns an object of class \verb+quantregForest+, for which \verb+print+, \verb+plot+ and \verb+predict+ methods are available.
In \verb+qrfozone+ the following information is stored:
<<>>=
print(qrfozone) # or simply just type qrfozone
@
The command \verb+print+ produces the output given above. It provides a summary over the input which was given to \verb+quantregForest+.
<<results=hide>>=
qrfozone$origNodes
@
This command returns the calculated nodes for the grown forest (330 values for each of the 100 trees), observation 1 lies in the nodes in row 1, observation 2 in the nodes in row 2 etc.
This is a difference to \verb+randomForest+, where per default these values are not saved.\\
To obtain the values of the response variable used to fit the model we can write:
<<results=hide>>=
qrfozone$origObs
@
This information is saved because it is used by the prediction algorithm.\\
The input parameter \verb+ntree+ determines how many trees are grown in the random forest on which quantile regression forests are based on. Empirical evidence suggests that the performance of the prediction remains good even when using only few trees. Therefore the default setting in the current version is 100 trees.
More parameters for tuning the growth of the trees are \verb+mtry+ and \verb+nodesize+. \verb+mtry+ sets the number of variables to try for each split when growing the tree. The same default is used as in \verb+randomForest+, which is one third of the number of predictors. The parameter \verb+nodesize+ fixes the minimal number of instances in each terminal node, determining how many observations at least lie in the same node. The default setting here is 10. As for the number of trees, varying this parameter does in general not make a big difference (quantile regression forests are very stable concerning these parameters) thus the default setting can often be used.\\
In analogy to \verb+randomForest+ there exists an input argument \verb+importance+ to compute a variable importance measure and related to that an input argument \verb+quantiles+. These are discussed further in Section \ref{sec:4}.\\
To summarize, growing quantile regression forests is basically the same as growing random forests but more information on the nodes is stored. The most important part of the package is the prediction function which is discussed in the next section.
\section{Prediction}
The prediction function in the current use has five input arguments with the following defaults:\\
<<echo=FALSE>>=
object<-qrfozone
@
<<results=hide>>=
predict(object, newdata=NULL,
		quantiles=c(0.1,0.5,0.9),
		all=FALSE, obs=1)
@
\verb+object+ has to be of class \verb+quantregForest+, i.e.\ a quantile regression forest grown as described in Section~\ref{sec:2}.\\
Consider first the simple input
<<results=hide>>=
predict(qrfozone)
@
where only the input \verb+object+ is set as the quantile regression forest grown for the \textit{Ozone} data. In this form, the function \verb+predict+ performs out-of-bag prediction on the dataset \textit{Ozone}, i.e.\ for each of the grown trees prediction for the data points which were not used for fitting the tree is done (no new data is involved).\\
The output is a $330 \times 3$ matrix with the predicted \textit{0.1, 0.5} and \textit{0.9} quantiles. If we only want to calculate one specific quantile, for example the median, we could type:
<<results=hide>>=
predict(qrfozone,quantiles=0.5)
@
The input for \verb+quantiles+ can be an arbitrary vector with values between 0 and~1. The default is \textit{(0.1, 0.5, 0.9)} as seen above.\\
To predict quantiles for new data the input \verb+newdata+ has to be changed to a matrix or data frame with new observations in the rows.\\
Consider thus prediction for \textit{Ozone} when only growing the quantile regression forest on the first 329 data points and use the 330th observation as new sample point:
<<>>=
xozone329 <- ozone[-330,-1]
yozone329 <- ozone$upo3[-330]
qrfozone329 <- quantregForest(xozone329,yozone329)
predict(qrfozone329,quantiles=0.5,newdata=ozone[330,-1])
@
Per default only one observation per node is used for prediction. This can be set with the input argument \verb+all+ with default \verb+all=FALSE+ (one observation per node used) and when setting \verb+all=TRUE+, all observation per node are used. The use of only one observation per node is of advantage especially when working with large datasets since the algorithm can be very slow otherwise. Numerical experiments suggest that the performance remains good.\\
Nevertheless, this option should be handled with care in cases with big datasets and few new sample points as input for \verb+newdata+ where setting \verb+all=FALSE+ may be significantly slower than choosing \verb+all=TRUE+.\\
The advantage of the fast implementation using only one observation per node for prediction can for example be seen when performing out-of-bag prediction on the large dataset \textit{CASP} with response variable \textit{RMSD} and 8 predictors when $10'000$ observations are used to fit the model and the quantiles for $1'000$ new sample points are predicted:
<<tidy=TRUE>>=
casp=read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/00265/CASP.csv")
xcasp <- casp[1:10000,-1]
ycasp <- casp$RMSD[1:10000]
qrfcasp <- quantregForest(xcasp,ycasp)
@
<<>>=
system.time(predict(qrfcasp,quantiles=0.5,newdata=casp[10001:11000,-1]))
@
As comparison consider the same setting but now all observations are used for prediction (\verb+all=TRUE+):
<<>>=
system.time(predict(qrfcasp,quantiles=0.5,newdata=casp[10001:11000,-1],all=TRUE))
@
We observe that the execution time in this case is indeed much longer when using all observations instead of only one observation per node for prediction.\\
Finally, there exists the option to change the number of observations per node used for prediction by the input argument \verb+obs+, which is only available for default setting \verb+all=FALSE+. The value 3 is chosen as example:
<<results=hide>>=
predict(qrfozone,quantiles=0.5,obs=3)
@
The default of \verb+obs+ is 1. Numerical experiments have shown that the results are already satisfying for \verb+obs=1+, so it is recommended to use the default here.\\
The question remains when to use which method, i.e.\ use all observations for prediction or only several observations per node. It depends mainly on the number of observations in the training dataset ($n_{\text{train}}$) and the number of observations in test data ($n_{\text{test}}$). To summarize, consider the following cases:
\begin{itemize}
\item Predict the quantiles for $n_{\text{train}}$ small and arbitrary $n_{\text{test}}$ or out-of-bag prediction: \verb+all=FALSE+ (default) or \verb+all=TRUE+ can be used since the results do not differ much and both options are fast.
\item Predict the quantiles for $n_{\text{train}}$ large and $n_{\text{test}}$ small (e.g.\ single new data point): Use \verb+all=TRUE+ since it is much faster.
\item Predict the quantiles for $n_{\text{train}}$ large and $n_{\text{test}}$ large or out-of-bag prediction: Use \verb+all=FALSE+ (default) since it is remarkably faster.
\end{itemize}
A method to plot data for class \verb+quantregForest+ is also made available in the package. With the command \verb+plot+ the 90 \% prediction interval for out-of-bag prediction is plotted. The input \verb+object+ has to be of class \verb+quantregForest+, see Figure \ref{ozoneplot} for the \textit{Ozone} dataset.
\begin{figure}
\begin{center}
<<label=ozoneplot,fig=TRUE>>=
plot(qrfozone)
@
\end{center}
\caption{Estimated 90 \% prediction intervals for the \textit{Ozone} dataset}
\label{ozoneplot}
\end{figure}
The red dots mark the observations which lie outside the prediction interval, the green ones lie inside. The grey bars represent the prediction intervals.\\
Again, per default \verb+all=FALSE+ is used which is reasonable since out-of-bag prediction is performed. Nevertheless, the option \verb+all=TRUE+ exists although it is recommended to use the default. The option to change the number of observations used for prediction is also available, but again it is recommended to use the default.
<<>>=
plot(qrfozone,all=TRUE)
plot(qrfozone,obs=3)
@
\section{Variable Importance}
\label{sec:4}
A variable importance measure for quantile regression forests can be obtained by the following steps:\\
First, when growing the tree with \verb+quantregForest+ the additional option \verb+importance+ has to be set to \verb+TRUE+, e.g.\ for the dataset \textit{Ozone}:
<<>>=
qrfozone <- quantregForest(xozone,yozone,importance=TRUE)
@
The quantiles for which the measure should be computed can be set by the input argument \verb+quantiles+. The default setting is \verb+quantiles=c(0.1,0.5,0.9)+. Arbitrary vectors with values between 0 and~1 are allowed.\\
The importance measure can then be extracted either using
<<results=hide>>=
qrfozone$importance
@
or the function \verb+importance+, both yield the same output:
<<>>=
importance(qrfozone)
@
The quantiles for which the measure should be returned can be set by the input argument \verb+quantiles+, e.g.\:
<<results=hide>>=
importance(qrfozone,quantile=0.5)
@
Per default the measures for all computed quantiles are returned. Only values for which the measure was already computed with \verb+quantregForest+ are allowed.\\
To visualize the variable importance measure the function \verb+varImpPlot.qrf+ can be used, see Figure \ref{varimpozone}.
\begin{figure}
\begin{center}
<<label=varimpozone,fig=TRUE>>=
varImpPlot.qrf(qrfozone)
@
\end{center}
\caption{Variable importance plot for \textit{Ozone}}
\label{varimpozone}
\end{figure}
\\
Again, the quantiles for which the measure should be visualized can be set by the input argument \verb+quantiles+. The same conditions need to be fulfilled as for \verb+importance+.\\
Additional options determining the design of the plot are available: \verb+sort+ determines if predictors should be sorted increasingly by the value of their importance measure, \verb+which.sort+ determines which quantile is relevant for the sorting and \verb+symbols+ and \verb+color+ determine if the plotted points should be symbols and/or coloured, consider e.g.\ the following possible input:
<<tidy=TRUE>>=
varImpPlot.qrf(qrfozone,quantiles=c(0.5,0.9),
symbols=FALSE,color=TRUE,which.sort=2)
@
For more details refer to the respective help files.
\section{Applications}
Quantile regression can be used in many different problems where one is not only interested in the conditional mean of a distribution but in the whole distribution. Two applications will be described here as they are highlighted in the original paper on quantile regression forests by Meinshausen \citep{MR2274394}.
\paragraph{Outlier Detection}
The first application discussed here is outlier detection. For illustrating this purpose, consider the \textit{Ozone} dataset, where three data points are manipulated, those with indices 50, 150 and 200. Then the 99\% quantiles are predicted and the indices of observations larger than the respective quantile are given as output.
<<>>=
ozoneoutliers <- ozone
ozoneoutliers$upo3[c(50,150,200)] <- ozoneoutliers$upo3[c(50,150,200)]*100
x <- ozoneoutliers[-1]
y <- ozoneoutliers$upo3
qrf <- quantregForest(x,y)
which(y>predict(qrf,quantile=0.99))
@
\paragraph{Prediction Intervals}
As already seen in the Figure \ref{ozoneplot}, it is quite easy to plot prediction intervals when working with quantile regression forests. A main conclusion that can be achieved by visualizing the prediction intervals is the reliability of a prediction, as the length of the prediction intervals differs strongly. As an  example consider the \textit{CASP} dataset, where the model is fitted on $10'000$ observations and the quantiles for 500 points are predicted. The result is displayed in Figure \ref{excasp} where we can conclude that for some observations the prediction is more reliable than for others.
<<tidy=TRUE>>=
quantiles <- c(0.05,0.5,0.95)
quant <- predict(qrfcasp,quantiles=quantiles,newdata=casp[11000:11500,-1])
z <- quant[,3]-quant[,1]
or <- order(z)
ynew <- casp$RMSD[11000:11500]
n <- length(ynew)

# center and order the quantiles

med <- quant[or,2]-quant[or,2]
upp <- quant[or,3]-quant[or,2]
low <- quant[or,1]-quant[or,2]
ytrain <- ynew[or]-quant[or,2]
@
\begin{figure}
\begin{center}
<<label=excasp,fig=TRUE,tidy=TRUE>>=
# Plot the centred observations and the prediction intervals

plot(1:n,ynew[or]-quant[or,2],pch=20,xlab="ordered samples", 
ylab="observed response and prediction 
intervals(centred)",type="n",main="90% prediction intervals") 

dist <- 0.01

for (i in 1:n){
  polygon( c(i-dist,i+dist,i+dist,i-dist), 
  c(upp[i],upp[i],low[i],low[i]) ,col=rgb(0.8,0.8,0.8) ,border=NA)
}
for (i in 1:n){
  lines(c(i-dist,i+dist) , c(upp[i],upp[i]) )
  lines(c(i-dist,i+dist) , c(low[i],low[i]) )
}

inpred <- (ytrain<= upp) & (ytrain>=low)
for (i in  1:n) points(i,ynew[or[i]]-quant[or[i],
2],col=as.numeric(inpred)[i]+2,pch=20)
@
\end{center}
\caption{Prediction intervals ordered according to their length for 500 samples of the \textit{CASP} dataset.}
\label{excasp}
\end{figure}
\clearpage
\bibliography{Lit}
\end{document}